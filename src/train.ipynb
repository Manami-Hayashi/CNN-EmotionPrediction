{
 "cells": [
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": [
    "# Train CNN Model\n",
    "\n",
    "This notebook contains the code to train a CNN model for emotion classification using the FERPlus dataset.\n",
    "\n",
    "## Imports"
   ],
   "id": "9d581d9843a509d3"
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-12-06T12:49:57.888550Z",
     "start_time": "2024-12-06T12:49:57.878547Z"
    }
   },
   "cell_type": "code",
   "source": [
    "import sys\n",
    "import time\n",
    "import os\n",
    "import math\n",
    "import csv\n",
    "import numpy as np\n",
    "import logging\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from torchvision import transforms\n",
    "from models import build_model\n",
    "from ferplus import FERPlusReader, FERPlusParameters, display_summary"
   ],
   "id": "870f47c2286cc2d2",
   "outputs": [],
   "execution_count": 6
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Helper Functions",
   "id": "c44f580e0342feba"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def cost_func(training_mode, prediction, target):\n",
    "    '''\n",
    "    We use cross entropy in most mode, except for the multi-label mode, which require treating\n",
    "    multiple labels exactly the same.\n",
    "    '''\n",
    "    if training_mode == 'majority' or training_mode == 'probability' or training_mode == 'crossentropy':\n",
    "        # Cross Entropy.\n",
    "        return nn.CrossEntropyLoss()(prediction, target)\n",
    "    elif training_mode == 'multi_target':\n",
    "        return nn.BCEWithLogitsLoss()(prediction, target)"
   ],
   "id": "dcd0059278fc72be"
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "## Main Function",
   "id": "8b579a9eb37fd0d0"
  },
  {
   "metadata": {},
   "cell_type": "code",
   "outputs": [],
   "execution_count": null,
   "source": [
    "def main(base_folder, training_mode='majority', model_name='VGG13', max_epochs=100):\n",
    "    output_model_path = os.path.join(base_folder, 'models')\n",
    "    output_model_folder = os.path.join(output_model_path, model_name + '_' + training_mode)\n",
    "    if not os.path.exists(output_model_folder):\n",
    "        os.makedirs(output_model_folder)\n",
    "\n",
    "    logging.basicConfig(filename=os.path.join(output_model_folder, \"train.log\"), filemode='w', level=logging.INFO)\n",
    "    logging.getLogger().addHandler(logging.StreamHandler())\n",
    "\n",
    "    logging.info(\"Starting with training mode {} using {} model and max epochs {}.\".format(training_mode, model_name, max_epochs))\n",
    "\n",
    "    num_classes = 8\n",
    "    model = build_model(num_classes, model_name)\n",
    "\n",
    "    input_var = torch.FloatTensor\n",
    "    label_var = torch.LongTensor\n",
    "\n",
    "    logging.info(\"Loading data...\")\n",
    "    train_params = FERPlusParameters(num_classes, 48, 48, training_mode, False)\n",
    "    test_and_val_params = FERPlusParameters(num_classes, 48, 48, \"majority\", True)\n",
    "\n",
    "    train_data_reader = FERPlusReader.create(base_folder, ['FER2013Train'], \"label.csv\", train_params)\n",
    "    val_data_reader = FERPlusReader.create(base_folder, ['FER2013Valid'], \"label.csv\", test_and_val_params)\n",
    "    test_data_reader = FERPlusReader.create(base_folder, ['FER2013Test'], \"label.csv\", test_and_val_params)\n",
    "\n",
    "    display_summary(train_data_reader, val_data_reader, test_data_reader)\n",
    "\n",
    "    optimizer = optim.SGD(model.parameters(), lr=0.01, momentum=0.9)\n",
    "    epoch_size = train_data_reader.size()\n",
    "    minibatch_size = 32\n",
    "\n",
    "    logging.info(\"Start training...\")\n",
    "    for epoch in range(max_epochs):\n",
    "        model.train()\n",
    "        train_data_reader.reset()\n",
    "        val_data_reader.reset()\n",
    "        test_data_reader.reset()\n",
    "\n",
    "        training_loss = 0\n",
    "        training_accuracy = 0\n",
    "        while train_data_reader.has_more():\n",
    "            images, labels, current_batch_size = train_data_reader.next_minibatch(minibatch_size)\n",
    "            images = torch.tensor(images, dtype=torch.float32)\n",
    "            labels = torch.tensor(labels, dtype=torch.long)\n",
    "\n",
    "            optimizer.zero_grad()\n",
    "            outputs = model(images)\n",
    "            loss = cost_func(training_mode, outputs, labels)\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "\n",
    "            training_loss += loss.item() * current_batch_size\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            training_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "        training_accuracy /= train_data_reader.size()\n",
    "        logging.info(\"Epoch {}: training loss: {:.4f}, training accuracy: {:.2f}%\".format(epoch, training_loss, training_accuracy * 100))\n",
    "\n",
    "        model.eval()\n",
    "        val_accuracy = 0\n",
    "        with torch.no_grad():\n",
    "            while val_data_reader.has_more():\n",
    "                images, labels, current_batch_size = val_data_reader.next_minibatch(minibatch_size)\n",
    "                images = torch.tensor(images, dtype=torch.float32)\n",
    "                labels = torch.tensor(labels, dtype=torch.long)\n",
    "                outputs = model(images)\n",
    "                _, predicted = torch.max(outputs, 1)\n",
    "                val_accuracy += (predicted == labels).sum().item()\n",
    "\n",
    "        val_accuracy /= val_data_reader.size()\n",
    "        logging.info(\"Epoch {}: validation accuracy: {:.2f}%\".format(epoch, val_accuracy * 100))"
   ],
   "id": "a9532743088a1fd8"
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 5,
 "nbformat_minor": 9
}
